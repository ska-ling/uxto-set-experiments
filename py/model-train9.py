import pandas as pd
import glob
import lightgbm as lgb
from pathlib import Path
import re
from sklearn.metrics import classification_report
import numpy as np


# === CONFIGURACIÃ“N ===
PARQUET_DIR = Path("/home/fernando/dev/utxo-experiments/parquet_normalized")
THRESHOLD = 1000  # bloques para considerar "hot"
EVAL_ROWS = 1_000_000  # cuÃ¡ntas filas usar para evaluaciÃ³n final
MODEL_PATH = "modelo-hotcold-batched.txt"

# === Ordenar archivos por Ã­ndice numÃ©rico
def extract_index(path):
    match = re.search(r'utxo-history-(\d+)\.parquet$', path)
    return int(match.group(1)) if match else -1

files = sorted(glob.glob(str(PARQUET_DIR / "utxo-history-*.parquet")), key=extract_index)

# === LightGBM config
params = {
    "objective": "binary",
    "metric": "binary_logloss",
    "learning_rate": 0.1,
    "num_leaves": 31,
    "num_threads": 60,
    "verbosity": -1,
    "scale_pos_weight": 0.4793 # 319_023_419 / 665_471_470 â‰ˆ 0.4793 ðŸ‘ˆ ajustar segÃºn la distribuciÃ³n
}

model = None
X_eval_list = []
y_eval_list = []
rows_seen = 0

# === Entrenamiento incremental por archivo
for path in files:
    print(f"Procesando: {path}")
    try:
        df = pd.read_parquet(path)

        # âœ… Target: si fue gastado y en corto plazo (<= threshold)
        df['hot'] = ((df['duration'] <= THRESHOLD) & df['event']).astype(int)

        # âœ… Features: solo campos disponibles en tiempo real
        features = [
            'value',
            'locking_script_size',
            'unlocking_script_size',
            'tx_coinbase',
            'op_return',
            'epoch',
            'creation_block'
        ]
        X = df[features]
        y = df['hot']

        # âœ… Acumular evaluaciÃ³n (opcional)
        if rows_seen < EVAL_ROWS:
            X_eval_list.append(X)
            y_eval_list.append(y)
            rows_seen += len(X)

        # âœ… Entrenamiento incremental
        train_set = lgb.Dataset(X, label=y)
        model = lgb.train(
            params,
            train_set,
            num_boost_round=20,
            init_model=model,
            keep_training_booster=True
        )

    except Exception as e:
        print(f"âŒ Error con {path}: {e}")

# === EvaluaciÃ³n final
print("\nðŸ“Š Evaluando sobre subset de evaluaciÃ³n...")
X_eval = pd.concat(X_eval_list)
y_eval = pd.concat(y_eval_list)

y_pred = model.predict(X_eval)
y_pred_class = (y_pred > 0.5).astype(int)

print(classification_report(y_eval, y_pred_class, digits=4))

print("\nðŸ”Ž Resumen de probabilidades predichas:")
print(pd.Series(y_pred).describe())
print("Ejemplos con probabilidad > 0.1:", np.sum(y_pred > 0.1))
print("Ejemplos con probabilidad > 0.5:", np.sum(y_pred > 0.5))


# === Guardar modelo
model.save_model(MODEL_PATH)
print(f"âœ… Modelo entrenado guardado en: {MODEL_PATH}")
